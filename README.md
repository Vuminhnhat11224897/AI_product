# ğŸš€ AI Production Pipeline# AI Production Pipeline



**Há»‡ thá»‘ng xá»­ lÃ½ dá»¯ liá»‡u tÃ i chÃ­nh tráº» em tá»± Ä‘á»™ng vá»›i AI****Production-grade AI batch processor for kids' financial behavior analysis** - Stable, configurable, and feature-complete with comprehensive logging and error handling.



## ğŸ“‹ TÃ­nh nÄƒng## ğŸ“‹ Tá»•ng Quan



- âœ… **Tá»± Ä‘á»™ng phÃ¡t hiá»‡n tuáº§n**: Tá»± Ä‘á»™ng detect cÃ¡c tuáº§n tá»« databasePipeline xá»­ lÃ½ AI vá»›i táº¥t cáº£ tÃ­nh nÄƒng production:

- âœ… **PhÃ¢n tÃ­ch xu hÆ°á»›ng**: So sÃ¡nh 2 tuáº§n trÆ°á»›c Ä‘á»ƒ phÃ¡t hiá»‡n tÄƒng/giáº£m- âœ… **Batch Processing**: Chia nhá» xá»­ lÃ½ theo lÃ´ cÃ³ thá»ƒ cáº¥u hÃ¬nh

- âœ… **AI Reports**: Táº¡o bÃ¡o cÃ¡o tá»± Ä‘á»™ng báº±ng GPT-4o- âœ… **Parallel Execution**: Cháº¡y song song cÃ³ kiá»ƒm soÃ¡t (semaphore pattern)

- âœ… **Tracking chi phÃ­**: Theo dÃµi token usage vÃ  chi phÃ­ API- âœ… **Rate Limiting**: Token bucket algorithm, tuÃ¢n thá»§ giá»›i háº¡n API

- âœ… **Production-ready**: Batch processing, retry, rate limiting- âœ… **Auto Retry**: Exponential backoff vá»›i retry configurable

- âœ… **Table Formatting**: Báº£ng káº¿t quáº£ Ä‘áº¹p vá»›i box drawing characters

## ğŸ—ï¸ Kiáº¿n trÃºc- âœ… **Comprehensive Logging**: Log Ä‘áº§y Ä‘á»§ tá»« code vÃ  API responses

- âœ… **Error Handling**: Production-ready error handling vÃ  recovery

```- âœ… **Zero Hardcode**: Táº¥t cáº£ config trong file YAML

Database (PostgreSQL)

    â†“## ğŸ—ï¸ Kiáº¿n TrÃºc

Silver Layer (Transform + Enrich + Trends)

    â†“ kids_analysis_week_N.json```

Gold Layer (AI Processing)ai-production-pipeline/

    â†“ kids_reports_week_N.jsonâ”œâ”€â”€ main.go                          # Entry point - orchestrates everything

Reportsâ”œâ”€â”€ config/

```â”‚   â””â”€â”€ config.yaml                  # All configuration (NO hardcode)

â”œâ”€â”€ internal/

## ğŸš€ Quick Startâ”‚   â””â”€â”€ processor/

â”‚       â”œâ”€â”€ processor.go             # AI processor core (batch, parallel, retry)

### Option 1: Docker (Recommended)â”‚       â””â”€â”€ formatter.go             # Table formatter for results

â”œâ”€â”€ data/

```bashâ”‚   â”œâ”€â”€ kids_analysis.json           # Input data

# 1. Copy environment fileâ”‚   â””â”€â”€ kids_report_*.json           # Output reports (timestamped)

cp .env.example .envâ”œâ”€â”€ logs/

â”‚   â””â”€â”€ ai_processor.log             # Application logs

# 2. Edit .env and add your OpenAI API keyâ”œâ”€â”€ .env                             # API keys (git-ignored)

nano .env  # or use any editorâ””â”€â”€ README.md                        # This file

```

# 3. Start all services

docker-compose up -d## ğŸš€ Quick Start (3 bÆ°á»›c)



# 4. Check logs### BÆ°á»›c 1: Setup Environment

docker-compose logs -f pipeline

```powershell

# 5. Stop servicescd d:\AI\ai-production-pipeline

docker-compose down

```# Táº¡o .env file vá»›i API key

"OPENAI_API_KEY=sk-your-actual-key-here" | Out-File -Encoding UTF8 .env

### Option 2: Local Development

# Install dependencies

```bashgo mod tidy

# 1. Install dependencies```

go mod download

### BÆ°á»›c 2: Cáº¥u HÃ¬nh (Optional)

# 2. Set environment variables

export OPENAI_API_KEY="sk-your-key"File `config/config.yaml` cÃ³ táº¥t cáº£ settings:



# 3. Run pipeline```yaml

go run main.go# Chá»‰nh batch size theo nhu cáº§u

batch:

# Or build and run  size: 5                    # Items per batch

go build -o pipeline.exe  max_concurrent: 3          # Max parallel calls

./pipeline.exe

```# Chá»‰nh rate limit theo API tier

rate_limit:

## âš™ï¸ Configuration  requests_per_minute: 50    # Adjust to your limit



Edit `config/config.yaml`:# Retry configuration

retry:

```yaml  max_attempts: 3

database:  exponential_backoff: true

  host: "localhost"      # "postgres" for Docker```

  port: 5432

  user: "postgres"### BÆ°á»›c 3: Cháº¡y

  password: "zseefvhu12"

  dbname: "testAI"```powershell

# CÃ¡ch 1: Run trá»±c tiáº¿p

openai:go run main.go

  model: "gpt-4o"

  max_tokens: 4000# CÃ¡ch 2: Build rá»“i cháº¡y

  temperature: 1.0go build -o pipeline.exe

.\pipeline.exe

batch:```

  size: 10

  max_concurrent: 10## ğŸ“Š Output



rate_limit:### Console Output

  requests_per_minute: 500

``````

ğŸš€ AI PRODUCTION PIPELINE STARTING

## ğŸ“Š Outputsâœ… AI Processor initialized

âœ… Rate limiter initialized

**Silver Layer** (`data/kids_analysis_week_N.json`):ğŸ“– Loading input data from: data/kids_analysis.json

- Dá»¯ liá»‡u Ä‘Ã£ transform vá»›i trends vÃ  statisticsâœ… Loaded 10 kids from input file

- 100 kids má»—i tuáº§nğŸš€ Starting AI batch processing...

- Historical comparison (2 weeks)

ğŸ“¦ Processing batch 1/2

**Gold Layer** (`data/kids_reports_week_N.json`):âœ… Item processed successfully (index: 0, tokens: 850)

- AI reports tá»« GPT-4oâœ… Item processed successfully (index: 1, tokens: 920)

- PhÃ¢n tÃ­ch xu hÆ°á»›ng, Ä‘á» xuáº¥t cáº£i thiá»‡nâœ… Batch completed

- Format JSON chuáº©n

ğŸ“Š Processing Statistics

## ğŸ“ˆ Token Usage Report  total_items: 10 | successful: 10 | failed: 0 | success_rate: 100.00%



Tá»± Ä‘á»™ng tracking vÃ  bÃ¡o cÃ¡o:âš¡ Performance Metrics

```  total_duration: 45.2s | average_per_item: 4.5s | total_retries: 0

Input tokens:  104,265 ($0.26)

Output tokens:  57,101 ($0.57)ğŸ¯ Token Usage

Total cost:     $0.83 USD  total_tokens: 8,750 | avg_tokens_per_item: 875

```

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—

## ğŸ§ª Generate Test Dataâ•‘                        FINAL PROCESSING SUMMARY                              â•‘

â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£

```bashâ•‘  Total: 10   |  Success: 10   |  Failed: 0   |  Success Rate: 100.00%       â•‘

cd scriptsâ•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

python generate_10kids_continuous_activity.py

```ğŸ’¾ Reports saved to: data/kids_report_20251016_165430.json

ğŸ‰ AI PRODUCTION PIPELINE COMPLETED SUCCESSFULLY

Táº¡o 10 kids vá»›i 6 tuáº§n hoáº¡t Ä‘á»™ng liÃªn tá»¥c.```



## ğŸ³ Docker Commands### File Output



```bash**`data/kids_report_20251016_165430.json`**:

# Build only```json

docker-compose build{

  "generated_at": "2025-10-16T16:54:30Z",

# Start services  "total_reports": 10,

docker-compose up -d  "reports": [

    {

# View logs      "nickname": "Alice",

docker-compose logs -f pipeline      "financial_health": "Excellent financial habits...",

      "spending_pattern": "Balanced spending across categories...",

# Restart pipeline      "savings_behavior": "Strong savings discipline...",

docker-compose restart pipeline      "recommendations": "1. Continue current...",

      "activity_level": "Highly engaged...",

# Stop all      "overall_score": 8.5,

docker-compose down      "generated_at": "2025-10-16T16:54:30Z"

    }

# Stop and remove volumes  ]

docker-compose down -v}

```

# Access database

docker exec -it ai-production-db psql -U postgres -d testAI## âš™ï¸ Configuration Chi Tiáº¿t



# Database admin UI### OpenAI Settings

# Open http://localhost:8080 (Adminer)

``````yaml

openai:

## ğŸ“ Project Structure  model: "gpt-4o-mini"         # Model name

  max_tokens: 2000             # Response limit

```  temperature: 0.7             # Creativity (0.0-1.0)

ai-production-pipeline/  timeout_seconds: 60          # Request timeout

â”œâ”€â”€ main.go                    # Entry point```

â”œâ”€â”€ Dockerfile                 # Docker build config

â”œâ”€â”€ docker-compose.yml         # Multi-container setup### Batch & Concurrency

â”œâ”€â”€ .dockerignore             # Docker ignore rules

â”œâ”€â”€ .env.example              # Environment template```yaml

â”‚batch:

â”œâ”€â”€ config/  size: 5                      # Items per batch (smaller = more frequent status updates)

â”‚   â””â”€â”€ config.yaml           # Main configuration  max_concurrent: 3            # Max parallel API calls (depends on rate limit)

â”‚```

â”œâ”€â”€ internal/

â”‚   â”œâ”€â”€ config/               # Config loader**Khuyáº¿n nghá»‹:**

â”‚   â”œâ”€â”€ constants/            # Shared constants- `size: 5-10` cho datasets nhá» (<50 items)

â”‚   â”œâ”€â”€ weekmanager/          # Week detection- `max_concurrent: 3-5` Ä‘á»ƒ khÃ´ng vÆ°á»£t rate limit

â”‚   â”œâ”€â”€ silver/               # Data transformation- TÄƒng `max_concurrent` náº¿u báº¡n cÃ³ tier cao hÆ¡n

â”‚   â”‚   â”œâ”€â”€ types.go

â”‚   â”‚   â””â”€â”€ silver_layer.go### Rate Limiting

â”‚   â”œâ”€â”€ gold/                 # AI processing

â”‚   â”‚   â””â”€â”€ gold_layer.go```yaml

â”‚   â””â”€â”€ processor/            # AI enginerate_limit:

â”‚       â”œâ”€â”€ processor.go  requests_per_minute: 50      # Must match your API tier

â”‚       â””â”€â”€ token_tracker.go```

â”‚

â”œâ”€â”€ prompts/**OpenAI Tiers:**

â”‚   â”œâ”€â”€ vietnamese_financial_report.txt- Free: 3 req/min

â”‚   â””â”€â”€ system_message.txt- Tier 1: 60 req/min

â”‚- Tier 2: 3,500 req/min

â”œâ”€â”€ scripts/

â”‚   â””â”€â”€ generate_10kids_continuous_activity.py### Retry Strategy

â”‚

â”œâ”€â”€ data/                     # Outputs (mounted in Docker)```yaml

â”‚   â”œâ”€â”€ kids_analysis_week_*.jsonretry:

â”‚   â””â”€â”€ kids_reports_week_*.json  max_attempts: 3                    # Total attempts (1 original + 3 retries)

â”‚  initial_delay_seconds: 2           # First retry delay

â””â”€â”€ logs/                     # Application logs  max_delay_seconds: 10              # Max delay cap

    â””â”€â”€ pipeline_*.log  exponential_backoff: true          # 2s â†’ 4s â†’ 8s (capped at 10s)

``````



## ğŸ”§ Troubleshooting### Logging



### Database connection error```yaml

```bashlogging:

# Check PostgreSQL is running  level: "info"                      # debug, info, warn, error

docker-compose ps  output: "both"                     # console, file, both

  log_dir: "logs"

# Check logs  log_file: "ai_processor.log"

docker-compose logs postgres  json_format: false                 # Set true for structured logs

  include_caller: true               # Show file:line in logs

# Test connection```

docker exec -it ai-production-db psql -U postgres -d testAI -c "SELECT 1"

```## ğŸ”§ Xá»­ LÃ½ Lá»—i



### OpenAI API errors### Rate Limit Errors

- Verify API key in `.env`

- Check rate limits (500 RPM for Tier 1)Pipeline tá»± Ä‘á»™ng:

- Monitor token usage in logs1. **Token bucket** kiá»ƒm soÃ¡t tá»‘c Ä‘á»™ requests

2. **Exponential backoff** khi gáº·p 429 errors

### Out of memory3. **Retry** tá»± Ä‘á»™ng vá»›i delay tÄƒng dáº§n

- Reduce `batch.max_concurrent` in config.yaml

- Increase Docker memory limit### Network Errors



## ğŸ’° Cost Estimation```

âš ï¸ Request failed, retrying...

**GPT-4o Pricing:**  attempt: 1/3 | error: connection timeout | retry_in: 2s

- Input: $2.50 / 1M tokensâš ï¸ Request failed, retrying...

- Output: $10.00 / 1M tokens  attempt: 2/3 | error: connection timeout | retry_in: 4s

âœ… Item processed successfully (index: 5, retries: 2)

**Typical run (100 kids Ã— 7 weeks = 700 AI calls):**```

- Input: ~150K tokens â†’ **$0.37**

- Output: ~80K tokens â†’ **$0.80**### API Errors

- **Total: ~$1.17 per full run**

CÃ¡c lá»—i API Ä‘Æ°á»£c log Ä‘áº§y Ä‘á»§:

## ğŸ“ License```

âŒ Item processing failed after all retries

MIT  index: 7 | retries: 3 | error: API error: insufficient_quota

```

## ğŸ¤ Support

### Context Cancellation

For issues or questions, create an issue on GitHub.

Nháº¥n `Ctrl+C` Ä‘á»ƒ graceful shutdown:
```
ğŸ›‘ Received interrupt signal, shutting down gracefully...
âš ï¸ Gold layer processing was cancelled
```

## ğŸ“ˆ Performance Monitoring

### Token Tracking

```yaml
monitoring:
  track_token_usage: true      # Log token consumption
```

Output:
```
ğŸ¯ Token Usage
  total_tokens: 8,750
  avg_tokens_per_item: 875
```

**Cost Estimation** (GPT-4o-mini):
- Input: $0.15 / 1M tokens
- Output: $0.60 / 1M tokens
- 10 kids Ã— 875 tokens â‰ˆ $0.005

### Timing Metrics

```yaml
monitoring:
  track_timing: true           # Log processing times
```

Output:
```
âš¡ Performance Metrics
  total_duration: 45.2s
  average_per_item: 4.5s
```

### Progress Updates

```yaml
monitoring:
  show_progress: true          # Real-time progress
```

Output:
```
ğŸ“Š Progress update: 3/10 (30.0%)
ğŸ“Š Progress update: 6/10 (60.0%)
ğŸ“Š Progress update: 10/10 (100.0%)
```

## ğŸ› ï¸ Troubleshooting

### Issue: "OPENAI_API_KEY not found"

```powershell
# Check if .env exists
Get-Content .env

# If not, create it:
"OPENAI_API_KEY=sk-your-key" | Out-File -Encoding UTF8 .env
```

### Issue: Rate limit errors

Giáº£m `max_concurrent` trong config:
```yaml
batch:
  max_concurrent: 2      # Reduce from 3 to 2
```

### Issue: Timeout errors

TÄƒng timeout:
```yaml
openai:
  timeout_seconds: 120   # Increase from 60 to 120
```

### Issue: Missing packages

```powershell
go mod tidy
go mod download
```

## ğŸ” Architecture Details

### 1. Main Flow (`main.go`)

```go
Load Config â†’ Setup Logger â†’ Load Data â†’ Process Batch â†’ Save Results
```

- Graceful shutdown vá»›i context cancellation
- Comprehensive error handling
- Config-driven, no hardcode

### 2. AI Processor (`internal/processor/processor.go`)

**Core Features:**

```go
// Batch processing with controlled concurrency
func ProcessBatch(ctx, items, promptTemplate) []ProcessResult

// Single item with retry logic
func processItemWithRetry(ctx, index, item, promptTemplate) ProcessResult

// Rate-limited API call
func callOpenAI(ctx, prompt) (output, usage, error)
```

**Token Bucket Rate Limiter:**
```go
type RateLimiter struct {
    tokens     chan struct{}      // Token bucket
    refillRate time.Duration      // Refill interval
}
```

### 3. Table Formatter (`internal/processor/formatter.go`)

```go
// Display results as table
func FormatResultsTable(results []ProcessResult)

// Calculate and display summary
func calculateSummary(results) ResultSummary
```

## ğŸ“ Best Practices

### 1. Config Management

- âœ… **DO**: Äáº·t táº¥t cáº£ settings trong `config.yaml`
- âœ… **DO**: API keys trong `.env` (git-ignored)
- âŒ **DON'T**: Hardcode values trong code

### 2. Error Handling

- âœ… **DO**: Log Ä‘áº§y Ä‘á»§ vá»›i context
- âœ… **DO**: Retry vá»›i exponential backoff
- âŒ **DON'T**: Silent failures

### 3. Performance

- âœ… **DO**: Monitor token usage
- âœ… **DO**: Adjust batch size theo dataset
- âœ… **DO**: Respect API rate limits
- âŒ **DON'T**: Set `max_concurrent` quÃ¡ cao

### 4. Production Deployment

- âœ… **DO**: Set `logging.output: "file"` hoáº·c `"both"`
- âœ… **DO**: Enable `json_format` cho log aggregation
- âœ… **DO**: Monitor logs directory size
- âŒ **DON'T**: Commit `.env` file

## ğŸ” Security

### Environment Variables

```powershell
# .env file structure
OPENAI_API_KEY=sk-proj-...
```

### .gitignore

```
.env
*.log
logs/
data/kids_report_*.json
*.exe
```

## ğŸ“š Dependencies

```go
require (
    github.com/joho/godotenv v1.5.1      // .env loading
    github.com/sirupsen/logrus v1.9.3    // Structured logging
    gopkg.in/yaml.v3 v3.0.1              // YAML parsing
)
```

## ğŸ¯ Production Checklist

- [x] âœ… KhÃ´ng cÃ³ hardcoded values
- [x] âœ… Táº¥t cáº£ config trong YAML
- [x] âœ… API keys trong environment variables
- [x] âœ… Comprehensive logging
- [x] âœ… Error handling vÃ  retry logic
- [x] âœ… Rate limiting
- [x] âœ… Graceful shutdown
- [x] âœ… Progress monitoring
- [x] âœ… Token usage tracking
- [x] âœ… Performance metrics
- [x] âœ… Formatted output (table + JSON)
- [x] âœ… Context cancellation support

## ğŸ“ Support

CÃ¡c lá»—i thÆ°á»ng gáº·p Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½ tá»± Ä‘á»™ng:
- âœ… Rate limit â†’ Automatic throttling
- âœ… Network errors â†’ Retry with backoff
- âœ… API errors â†’ Logged vá»›i full context
- âœ… Timeout â†’ Configurable timeouts
- âœ… Invalid data â†’ Graceful skip vá»›i warning

---

**Ready for Production** ğŸš€ - Code á»•n Ä‘á»‹nh, Ä‘áº§y Ä‘á»§ tÃ­nh nÄƒng, dá»… maintain!
